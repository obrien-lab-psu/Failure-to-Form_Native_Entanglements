#!/usr/bin/env python3
import logging, os, sys
import time
import argparse
import pandas as pd
import numpy as np
import glob
import matplotlib.pyplot as plt
from matplotlib.cm import get_cmap
import matplotlib.cm as cm
from matplotlib.colors import ListedColormap, BoundaryNorm
import matplotlib.colors as mcolors
import seaborn as sns
from scipy.stats import mode, permutation_test, ttest_1samp, ttest_ind
import pickle
#pd.set_option('display.max_rows', 5000)

class Analysis:
    """
    A class to perform analysis on Molecular dynamics trajecotry data and plot the results. 
    """
    #######################################################################################
    def __init__(self, args):
        """
        Initializes the DataAnalysis class with necessary paths and parameters.

        Parameters:
        ("--outpath", type=str, required=True, help="Path to output directory")
        ("--candidates", type=str, required=True, help="A file containing two columns. The candidate tag and the groupID")
        ("--toplevel", type=str, required=True, help="file containing relative paths to either native state GQ files or the MSM file for various proteins")
        ("--outname", type=str, required=True, help="base name for output files")
        ("--Mirrorfile", type=str, required=True, help="file containing trajectories identified as a mirror")
        """

        # parse the parameters 
        self.candidates = pd.read_csv(args.candidates)
        logging.info(f'candidates:\n{self.candidates}')

        self.outpath = args.outpath
        logging.info(f'outpath: {self.outpath}')

        self.outname = args.outname
        logging.info(f'outname: {self.outname}')

        self.toplevel = args.toplevel
        logging.info(f'toplevel: {self.toplevel}')
        print(f'toplevel: {self.toplevel}')

        self.Mirrorfile = args.Mirrorfile
        print(f'Mirrorfile: {self.Mirrorfile}')
        self.Mirror_df = pd.read_csv(self.Mirrorfile)
        self.Mirror_df = self.Mirror_df[self.Mirror_df['Mirror'] == 'Y']

        ## Get the set of clustered entanglement files
        self.ClusterEntInfoFiles = glob.glob(os.path.join(self.toplevel, '*/Cluster_ChangesInEnt/*_clustered.EntInfo'))
        print(f'Number of clustered EntInfo files found: {len(self.ClusterEntInfoFiles)}')

        ## get the set of G, Q, and K files
        self.QFiles = glob.glob(os.path.join(self.toplevel, '*/Q/*.Q'))
        print(f'Number of Q files found: {len(self.QFiles)}')

        self.GFiles = glob.glob(os.path.join(self.toplevel, '*/G/*.G'))
        print(f'Number of G files found: {len(self.GFiles)}')

        self.KFiles = glob.glob(os.path.join(self.toplevel, '*/Mirror/Quench/*.dat'))
        print(f'Number of K files found: {len(self.KFiles)}')

        ## get the set of native G, Q, and K files
        self.nQFiles = glob.glob(os.path.join(self.toplevel, '*/Native/Q/*.Q'))
        print(f'Number of Native Q files found: {len(self.QFiles)}')

        self.nGFiles = glob.glob(os.path.join(self.toplevel, '*/Native/G/*.G'))
        print(f'Number of Native G files found: {len(self.GFiles)}')

        self.nKFiles = glob.glob(os.path.join(self.toplevel, '*/Mirror/Native/*.dat'))
        print(f'Number of Native K files found: {len(self.KFiles)}')

        ## get the MSM files
        self.MSMFiles = glob.glob(os.path.join(self.toplevel, '*/BuildKineticModel/*_MSMmapping.csv'))
        print(f'Number of MSM files found: {len(self.KFiles)}')

        ## make Plots dir
        self.plot_path = os.path.join(self.outpath, 'Plots')
        if not os.path.exists(self.plot_path):
            os.makedirs(self.plot_path)
            print(f'Made directory: {self.plot_path}')  
        print(f'plot_path: {self.plot_path}') 
        
        ## make logging dir
        self.data_path = os.path.join(self.outpath, 'DATA')
        if not os.path.exists(self.data_path):
            os.makedirs(self.data_path)
            print(f'Made directory: {self.data_path}')   
    #######################################################################################

    #######################################################################################
    def load_OP(self,):
        """
        Loops through the file paths in the GQfiles file and determines if it is either 
        1. GQ data from the native sims
        2. MSM data file 
        3. the tag is in the caidate list
        and loads the data as appropriate
        """

        data = {}
        print(self.candidates)
        for gene, pdb, chain in self.candidates[['gene', 'pdb', 'chain']].values:
            tag = f'{gene}_{pdb}_{chain}'
            print(f'Loading files for {gene} {pdb} {chain} {tag}')

            if tag not in data:
                data[tag] = {'Q':{'Native':{}, 'Quench':{}}, 'G':{'Native':{}, 'Quench':{}}, 'K':{'Native':{}, 'Quench':{}}, 
                            'Qstats':{'Native':[], 'Quench':[]}, 'Gstats':{'Native':[], 'Quench':[]}, 'Kstats':{'Native':[], 'Quench':[]}, 
                            'MSM':{'Qstats':{}, 'Gstats':{}, 'Kstats':{}}, 'df':pd.DataFrame()}

            ###########################################################################
            ## Load Quench Q, G, K data
            QFiles = [f for f in self.QFiles if tag in f]
            print(f'QFiles: {len(QFiles)}')
            for f in QFiles:
                traj = f.split('_')[-1].replace('t', '').replace('.Q', '')
                #print(f, traj)
                data[tag]['Q']['Quench'][traj] = pd.read_csv(f)['Q'].values
              
            GFiles = [f for f in self.GFiles if tag in f]
            print(f'GFiles: {len(GFiles)}')
            for f in GFiles:
                traj = f.split('_')[-1].replace('t', '').replace('.G', '')
                #print(f, traj)
                data[tag]['G']['Quench'][traj] = pd.read_csv(f)['G'].values

            KFiles = [f for f in self.KFiles if tag in f]
            print(f'KFiles: {len(KFiles)}')
            for f in KFiles:
                traj = f.split('_')[-2].replace('t', '')
                #print(f, traj)
                data[tag]['K']['Quench'][traj] = np.loadtxt(f, usecols=(-1), dtype=str)[1:].astype(float)

            ###########################################################################
            ## Load Native Q, G, K data
            QFiles = [f for f in self.nQFiles if tag in f]
            print(f'QFiles: {len(QFiles)}')
            for f in QFiles:
                traj = f.split('_')[-1].replace('t', '').replace('.Q', '')
                #print(f, traj)
                data[tag]['Q']['Native'][traj] = pd.read_csv(f)['Q'].values
              
            GFiles = [f for f in self.nGFiles if tag in f]
            print(f'GFiles: {len(GFiles)}')
            for f in GFiles:
                traj = f.split('_')[-1].replace('t', '').replace('.G', '')
                #print(f, traj)
                data[tag]['G']['Native'][traj] = pd.read_csv(f)['G'].values

            KFiles = [f for f in self.nKFiles if tag in f]
            print(f'KFiles: {len(KFiles)}')
            for f in KFiles:
                traj = f.split('_')[-1].replace('.dat', '')
                #print(f, traj)
                data[tag]['K']['Native'][traj] = np.loadtxt(f, usecols=(-1), dtype=str)[1:].astype(float)

            ###########################################################################
            ## Load MSM files
            MSMFiles = [f for f in self.MSMFiles if tag in f]
            if len(MSMFiles) > 1:
                raise ValueError(f"There should only be 1 or 0 MSM file but there are {len(MSMFiles)}")
                
            if MSMFiles:
                df = pd.read_csv(MSMFiles[0])
                df['K'] = np.nan

                ## add the K data to a column for easy manipulation later 
                for traj, traj_df in df.groupby('traj'):
                    traj_K = data[tag]['K']['Quench'][str(traj)]
                    if len(traj_df) == len(traj_K):
                        df.loc[traj_df.index,'K'] = traj_K
                    else:
                        raise ValueError(f'The length of the MSM traj {len(traj_df)} != the K values {len(traj_K)}')

                ## remove any traj that has been identified to have a mirror
                Mirrors = self.Mirror_df[(self.Mirror_df['gene'] == gene) & (self.Mirror_df['pdb'] == pdb) & (self.Mirror_df['chain'] == chain)]
                Mirror_trajs = Mirrors['traj'].values
                print(f'Mirror_trajs: {Mirror_trajs}')
                df = df[~df['traj'].isin(Mirror_trajs)]
                data[tag]['df'] = df

        self.data = data
        logging.info(f'Number of genes in data: {len(self.data)}')    
        print(f'Number of genes in data: {len(self.data)}')            
    #######################################################################################  

    #######################################################################################
    def get_nativeSIM_stats(self,):
        """
        Get the <> and 95% ci for G and Q in the native state sims
        """
        #print(self.candidates)
        self.stats_df = {'gene_tag':[], 'macrostateID':[], 'desc':[], 'Qmean':[], 'Qstd':[], 'Q_lb':[], 'Q_ub':[], 
                        'Gmean':[], 'Gstd':[], 'G_lb':[], 'G_ub':[], 'Kmean':[], 'Kstd':[], 'K_lb':[], 'K_ub':[], 'n':[], 'native':[]}
        for tag, tag_data in self.data.items():
            Qdata = np.hstack(list(tag_data["Q"]['Native'].values()))
            Gdata = np.hstack(list(tag_data["G"]['Native'].values()))
            Kdata = np.hstack(list(tag_data["K"]['Native'].values()))
            print(f'{tag} with {len(Qdata)} {Qdata.shape} Q arrays | {len(Gdata)} {Gdata.shape} G arrays | {len(Kdata)} {Kdata.shape} K arrays')

            Qmedian, Qmean, Qstd, Q_lb, Q_ub = get_stats(Qdata)
            Gmedian, Gmean, Gstd, G_lb, G_ub = get_stats(Gdata)
            Kmedian, Kmean, Kstd, K_lb, K_ub = get_stats(Kdata)
            print(f'<Q> = {Qmean} | std(Q) = {Qstd} | 95%ci = ({Q_lb}, {Q_ub})')
            print(f'<G> = {Gmean} | std(G) = {Gstd} | 95%ci = ({G_lb}, {G_ub})')
            print(f'<K> = {Kmean} | std(K) = {Kstd} | 95%ci = ({K_lb}, {K_ub})')

            self.data[tag]['Qstats']['Native'] = (Qmean, Qstd, Q_lb, Q_ub)
            self.data[tag]['Gstats']['Native'] = (Gmean, Gstd, G_lb, G_ub)
            self.data[tag]['Kstats']['Native'] = (Kmean, Kstd, K_lb, K_ub)

            self.stats_df['gene_tag'] += [tag]
            self.stats_df['macrostateID'] += [-1]
            self.stats_df['desc'] += ['Ref State Sims']
            self.stats_df['Qmean'] += [Qmean]
            self.stats_df['Qstd'] += [Qstd]
            self.stats_df['Q_lb'] += [Q_lb]
            self.stats_df['Q_ub'] += [Q_ub]
            self.stats_df['Gmean'] += [Gmean]
            self.stats_df['Gstd'] += [Gstd]
            self.stats_df['G_lb'] += [G_lb]
            self.stats_df['G_ub'] += [G_ub]
            self.stats_df['Kmean'] += [Kmean]
            self.stats_df['Kstd'] += [Kstd]
            self.stats_df['K_lb'] += [K_lb]
            self.stats_df['K_ub'] += [K_ub]
            self.stats_df['n'] += [len(Qdata)]
            self.stats_df['native'] += [True]
          
    #######################################################################################

    #######################################################################################
    def find_native_state(self, ):
        """
        For each candidate find the native state amongst the MSM data defined by the highest <Q> and lowest <G>
        Tag this state in a new column called NativeByMSM in the self.data[tag]['MSM'] dataframe
        Also find native frames by using the Q >= <Q>ns - 3*sigma and G <= <G>ns + 3*sigma and tag a column named NativeByRef in the self.data[tag]['MSM'] dataframe
        """
        print(f'Find the native states by MSM and Ref')
        ###################################################################################################
        for tag, tag_data in self.data.items():
            df = tag_data['df']

            if len(df) != 0:
                #print(f'df {tag}\n{df}')

                local_mss_GQmeans = {'mssID':[], 'Qmean':[], 'Gmean':[]}
                for mssID, mss_df in df.groupby(['metastablestate']):
                    mssID = mssID[0]
                    #print(mssID, mss_df)
                    
                    Qmedian, Qmean, Qstd, Q_lb, Q_ub = get_stats(mss_df['Q'].values)
                    mssID_Qstats = (Qmean, Qstd, Q_lb, Q_ub)

                    Gmedian, Gmean, Gstd, G_lb, G_ub = get_stats(mss_df['G'].values)
                    mssID_Gstats = (Gmean, Gstd, G_lb, G_ub)

                    Kmedian, Kmean, Kstd, K_lb, K_ub = get_stats(mss_df['K'].values)
                    mssID_Kstats = (Kmean, Kstd, K_lb, K_ub)

                    #print(f'<Q> = {Qmean} | std(Q) = {Qstd} | 95%ci = ({Q_lb}, {Q_ub})')
                    #print(f'<G> = {Gmean} | std(G) = {Gstd} | 95%ci = ({G_lb}, {G_ub})')
                    #print(f'<K> = {Kmean} | std(K) = {Kstd} | 95%ci = ({K_lb}, {K_ub})')

                    ## update dictionary traccking the mean G and Q for this protein only
                    local_mss_GQmeans['mssID'] += [mssID]
                    local_mss_GQmeans['Qmean'] += [Qmean]
                    local_mss_GQmeans['Gmean'] += [Gmean]

                    ## update the global self.data dictionary MSM level with the Q and G stats
                    self.data[tag]['MSM']['Qstats'][mssID] = mssID_Qstats
                    self.data[tag]['MSM']['Gstats'][mssID] = mssID_Gstats
                    self.data[tag]['MSM']['Kstats'][mssID] = mssID_Kstats

                # determine the native MSM state by the highest <Q> and lowest <G>
                logging.info(f'Determine the native MSM state by the highest <Q> and lowest <G>')
                local_mss_GQmeans = pd.DataFrame(local_mss_GQmeans)
                local_mss_GQmeans = local_mss_GQmeans.sort_values(by=['Qmean', 'Gmean'], ascending=False, ignore_index=True)
                #print(local_mss_GQmeans)
                nativeMSS = local_mss_GQmeans.iloc[0]['mssID']
                logging.info(f'{tag} | nativeMSS: {nativeMSS}')
                df['NativeByMSS'] = df['metastablestate'] == nativeMSS

                # determine the native frames by having a Q and G within 3sigma of the reference sim averages
                logging.info(f'Determine the native frames by having a Q and G within 3sigma of the reference sim averages')
                Native_Qmean = self.data[tag]['Qstats']['Native'][0] 
                Native_Qstd = self.data[tag]['Qstats']['Native'][1]
                Qthreshold = Native_Qmean - 3*Native_Qstd
                logging.info(f'Native_Qmean: {Native_Qmean} | Native_Qstd: {Native_Qstd} | Qthreshold: {Qthreshold}')

                Native_Gmean = self.data[tag]['Gstats']['Native'][0] 
                Native_Gstd = self.data[tag]['Gstats']['Native'][1]
                Gthreshold = Native_Gmean + 3*Native_Gstd
                logging.info(f'Native_Gmean: {Native_Gmean} | Native_Gstd: {Native_Gstd} | Gthreshold: {Gthreshold}')

                df['NativeByRef'] = (df['Q'] >= Qthreshold) & (df['G'] <= Gthreshold)


                ###################################################################################################
                ## loop through again now that we have assigned native frames and MSM stateas and make a summary stats file for output
                for mssID, mss_df in df.groupby(['metastablestate']):
                    mssID = mssID[0]
                    #print(mss_df)

                    mssID_Qstats = self.data[tag]['MSM']['Qstats'][mssID]
                    Qmean, Qstd, Q_lb, Q_ub = mssID_Qstats

                    mssID_Gstats = self.data[tag]['MSM']['Gstats'][mssID]
                    Gmean, Gstd, G_lb, G_ub = mssID_Gstats

                    mssID_Kstats = self.data[tag]['MSM']['Kstats'][mssID]
                    Kmean, Kstd, K_lb, K_ub = mssID_Kstats

                    ## update the stats dataframe containing just high level stats info for each set of Q and G values analuzed
                    self.stats_df['gene_tag'] += [tag]
                    self.stats_df['macrostateID'] += [mssID]
                    self.stats_df['desc'] += ['T-Quench sims']
                    self.stats_df['Qmean'] += [Qmean]
                    self.stats_df['Qstd'] += [Qstd]
                    self.stats_df['Q_lb'] += [Q_lb]
                    self.stats_df['Q_ub'] += [Q_ub]
                    self.stats_df['Gmean'] += [Gmean]
                    self.stats_df['Gstd'] += [Gstd]
                    self.stats_df['G_lb'] += [G_lb]
                    self.stats_df['G_ub'] += [G_ub]
                    self.stats_df['Kmean'] += [Kmean]
                    self.stats_df['Kstd'] += [Kstd]
                    self.stats_df['K_lb'] += [K_lb]
                    self.stats_df['K_ub'] += [K_ub]
                    self.stats_df['n'] += [len(mss_df)]
                    if mssID == nativeMSS:
                        self.stats_df['native'] += [True]
                    else:
                         self.stats_df['native'] += [False]
                

        self.stats_df = pd.DataFrame(self.stats_df)
        logging.info(f'self.stats_df:\n{self.stats_df}')
        stats_outfile = os.path.join(self.data_path, f'GQstats.csv')
        self.stats_df.to_csv(stats_outfile, index=False)
        logging.info(f'SAVED: {stats_outfile}')
        print(self.stats_df)
        ###################################################################################################

        ###################################################################################################
        ## Plot the stats_df results
        # for each protein plot the GvQ scatter plot with Q and G 95% confidence intervals
        for setID in [1,2]:
            set_candidates = self.candidates[self.candidates['set'] == setID]

            # Create a 3x4 figure
            fig, axes = plt.subplots(3, 3, figsize=(15, 10))
            #fig.tight_layout(pad=3.0)

            # Flatten the axes array
            axes = axes.flatten()

            for i, (gene, pdb, chain, setID, set_name) in enumerate(set_candidates.values):

                tag = f'{gene}_{pdb}_{chain}'
                logging.info(f'{i}, {gene}, {pdb}, {chain}, {setID}, {set_name}')
               
                # get section of stats for this tag
                tag_df = self.stats_df[self.stats_df['gene_tag'] == tag]
                tag_df['p'] = tag_df['n']/np.sum(tag_df['n'].values)
                #print(tag_df)

                # Extract data
                x = tag_df['Qmean'].values
                y = tag_df['Gmean'].values
                #xerr = [tag_df['Qmean'].values - tag_df['Q_lb'].values, tag_df['Q_ub'].values - tag_df['Qmean'].values]
                #yerr = [tag_df['Gmean'].values - tag_df['G_lb'].values, tag_df['G_ub'].values - tag_df['Gmean'].values]
                xerr = [3*tag_df['Qstd'].values, 3*tag_df['Qstd'].values]
                yerr = [3*tag_df['Gstd'].values, 3*tag_df['Gstd'].values]
                occupancy = tag_df['p']
                labels = tag_df['macrostateID'].values

                # Generate unique colors for each data point using a colormap
                colors = cm.get_cmap('tab20', len(tag_df))  # 'tab20' provides up to 20 distinct colors

                # Create error bar plot with dynamic colors and legend
                for j in range(len(tag_df)):
                    marker = 'o'
                    if str(labels[j]) == '-1':
                        marker = 'X'
                    axes[i].errorbar(x[j], y[j], xerr=[[xerr[0][j]], [xerr[1][j]]], yerr=[[yerr[0][j]], [yerr[1][j]]],
                                marker=marker, color=colors(j), label=str(labels[j]), alpha=1.0, capsize=3)

                # Add legend
                axes[i].legend(title='stateID', loc='best', bbox_to_anchor=(1, 1), ncol=2)
                # Create scatter plot with error bars
                #axes[i].errorbar(x, y, xerr=xerr, yerr=yerr, fmt='o', alpha=1.0, label=labels, markersize=5)

                # Labels and title
                axes[i].set_xlabel('Q')
                axes[i].set_ylabel('G')
                axes[i].set_title(tag)
                axes[i].grid(True)

            plt.suptitle(f'Dataset {setID}')
            plt.tight_layout()
            outfile = os.path.join(self.plot_path, f'dataset{setID}_GQ.png')
            plt.savefig(outfile)
            logging.info(f'SAVED: {outfile}')
    ###################################################################################################
    #######################################################################################

    #######################################################################################
    def CalcFractMisfolded(self, NativeBy='MSM', scope='full'):
        """
        Calculate the ratio of misfolded and native frames in each trajectory 
        Do it for the full trajectory and every 10% percentile buckets
        Apply a blanket Q threshold and only consider structures with Q > 0.6
        NativeBy: can be MSM, Ref, or None
            MSM = using the metastable state with the highest <Q> and lowest <G> as the native state. Will examine all frames outside this native meta stable state.
            Ref = using <Qref> - 3*sigma and <Gref> + 3*sigma as thresholds for selecting native frames. Will examine all frames with Q greater than the threshold and G less than. 
            None = No native defined frames. examine all frames. 
        scope: defines the scope of the analysis. full analyzes the whole GQ data and last10 only uses the last 10% of the traj
        """

        num_chunks = 10
        #print(f'num_chunks: {num_chunks}')
        #################################################
        ## Determine the scope of the analysis
        if scope in ['full', 'last10']:
            if scope == 'full':
                scope_dict = {0:'full', 1:'0-10%', 2:'10-20%', 3:'20-30%', 4:'30-40%', 5:'40-50%', 6:'50-60%', 7:'60-70%', 8:'70-80%', 9:'80-90%', 10:'90-100%'}
                fract_misfolded_df = {'tag':[], 'setID':[], 'traj':[], 'NativeBy':[], 'Metric':[],
                    'full':[], '0-10%':[], '10-20%':[], '20-30%':[], '30-40%':[], 
                    '40-50%':[], '50-60%':[], '60-70%':[], '70-80%':[], '80-90%':[], '90-100%':[]}
            else:
                scope_dict = {0:'full', 10:'90-100%'}
                fract_misfolded_df = {'tag':[], 'setID':[], 'traj':[], 'NativeBy':[], 'Metric':[],
                    'full':[], '90-100%':[]}
        else:
            raise ValueError(f'Scope can only be full or last10')


        #####################################################
        ## Get the frame chunks to split the analysis on
        FrameEnd = 26666
        print(f'FrameEnd: {FrameEnd}')
        # Split the array into 10 equal chunks
        frame_chunks = [np.arange(0, FrameEnd + 1)] + np.array_split(np.arange(0, FrameEnd + 1), 10)
        print(f'frame_chunks: {frame_chunks}')

        ####################################################
        # Calculate R for each traj in sets 1 and 2
        for gene, pdb, chain, setID, set_name in self.candidates.values:

            tag = f'{gene}_{pdb}_{chain}'
            #print(gene, pdb, chain, setID, set_name)

            if setID in [1,2]:

                msm = self.data[tag]['df'] 
                #trunc_msm = msm[msm['Q'] >= 0.6]

                for traj, traj_df in msm.groupby('traj'):
                    #print(traj_df)
                    fract_misfolded_df['tag'] += [tag]
                    fract_misfolded_df['setID'] += [setID]
                    fract_misfolded_df['traj'] += [traj]
                    fract_misfolded_df['NativeBy'] += [NativeBy]
                    fract_misfolded_df['Metric'] += ['FracMisfolded']

                    for i,label in scope_dict.items():
                        # Calculate the percentile range
                        lower_bound = frame_chunks[i][0]
                        upper_bound = frame_chunks[i][-1]
                        lower_bound, upper_bound = int(lower_bound), int(upper_bound)
                        #print(i, lower_bound, upper_bound)
                        
                        # Filter the DataFrame for rows within this percentile range
                        chunk = traj_df[(traj_df['frame'] >= lower_bound) & (traj_df['frame'] < upper_bound)]
                        #print(chunk)
                        if len(chunk) == 0:
                            R = np.nan
                        else:
                            R = np.mean(chunk[f'NativeBy{NativeBy}'].values)
                        fract_misfolded_df[label] += [R]

        fract_misfolded_df = pd.DataFrame(fract_misfolded_df)           
        logging.info(f'fract_misfolded_df:\n{fract_misfolded_df}')
        outfile = os.path.join(self.data_path, f'FracMisfolded_Scope-{scope}_NativeBy{NativeBy}.csv')
        fract_misfolded_df.to_csv(outfile, index=False)
        logging.info(f'SAVED: {outfile}')
        return fract_misfolded_df
    ########################################################################################

    #######################################################################################
    def OneSampleStats(self, df, setID=2, NativeBy='MSM', test_mean=1, label='None', scope='full'):
        """
        Calculate the OneSampleStats for any metric: Avg, Median, std, 95% ci of the mean, 1sample ttest stat and pvalue
        setID is an integer to be used to select the data
        df is a metric dataframe 
        NativeBy: can be MSM, Ref, or None
            MSM = using the metastable state with the highest <Q> and lowest <G> as the native state. Will examine all frames outside this native meta stable state.
            Ref = using <Qref> - 3*sigma and <Gref> + 3*sigma as thresholds for selecting native frames. Will examine all frames with Q greater than the threshold and G less than. 
            None = No native defined frames. examine all frames. 
        test_mean is the population mean used in the 1sample ttest
        outfiletag is just a string appended to the image file name
        scope is the level at which data was analyzed. all chunks of the trajectory were analyzed (full) or just the last 10% (last10)
        """
        logging.info(f'Performing 1 sample T-Test on {label} data for setID: {setID} and NativeBy: {NativeBy}')
        df = df[(df['setID'] == setID) & (df['NativeBy']==NativeBy)]
        print(f'{label}_df:\n{df}')

        #################################################
        ## Determine the scope of the analysis
        if scope in ['full', 'last10']:
            if scope == 'full':
                scope_list = [f'full', f'0-10%', f'10-20%', f'20-30%', f'30-40%', f'40-50%', f'50-60%', f'60-70%', f'70-80%', f'80-90%', f'90-100%']
            else:
                scope_list = [f'90-100%']

        else:
            raise ValueError(f'Scope can only be full or last10')

        ########################################################################################
        ## for each protein calculate the <R> and confidence intervals 
        df_stats = {'setID':[], 'NativeBy':[], 'Label':[], 'Metric':[], 'median':[], 'avg':[], 'std':[], 'lb':[], 'ub':[], 'ttest':[], 'pvalue':[]}

        for key in scope_list:
            df_stats['setID'] += [setID]
            df_stats['NativeBy'] += [NativeBy]
            df_stats['Label'] += [key]
            df_stats['Metric'] += [label]
            
            #drop -1 values and replace np.inf values with the largest OddsLoss
            data = df[key].values
            data = data[np.where(data != -1)]
            max_finite_value = np.max(data[np.isfinite(data)])
            data[data == np.inf] = max_finite_value

            median, mean, std, lb, ub = get_stats(data)
            # Perform the one-sample t-test
            if test_mean == None:
                t_statistic, p_value = np.nan, np.nan
            else:
                t_statistic, p_value = ttest_1samp(data, test_mean)

            #print(f'setID {setID} | NativeBy {NativeBy} | {key} | <{label}> = {mean} +/- ({lb}, {ub}) | simga({label}) = {std} | t_statistic: {t_statistic} w/ p_value: {p_value}')
            df_stats[f'median'] += [median]
            df_stats[f'avg'] += [mean]
            df_stats[f'std'] += [std]
            df_stats[f'lb'] += [lb]
            df_stats[f'ub'] += [ub]
            df_stats[f'ttest'] += [t_statistic]
            df_stats[f'pvalue'] += [p_value]

        df_stats = pd.DataFrame(df_stats)
        print(f'{label} df_stats:\n{df_stats}')
        outfile = os.path.join(self.data_path, f'{label}_setID{setID}_OneSampleStats_{scope}_NativeBy{NativeBy}.csv')
        df_stats.to_csv(outfile, index=False)
        logging.info(f'SAVED: {outfile}')  
        return df_stats   
    #######################################################################################

    #######################################################################################
    def TwoSampleStats(self, df, setIDs=(1,2), NativeBy='MSM', test='permutation', label='Fract_misfolded', scope='full'):
        """
        Calculate the TwoSampleStats for any metric between two sets of data using either permutation or ttest
        setIDs is a tuple of two setIDs to be used to select the data
        df is a metric dataframe 
        NativeBy: can be MSM, Ref, or None
            MSM = using the metastable state with the highest <Q> and lowest <G> as the native state. Will examine all frames outside this native meta stable state.
            Ref = using <Qref> - 3*sigma and <Gref> + 3*sigma as thresholds for selecting native frames. Will examine all frames with Q greater than the threshold and G less than. 
            None = No native defined frames. examine all frames. 
        test is permutation or ttest depending on which test you want to perform
        outfiletag is just a string appended to the image file name
        scope is the level at which data was analyzed. all chunks of the trajectory were analyzed (full) or just the last 10% (last10)
        """
        print(f'Performing {test} on {label} data for setID: {setIDs} and NativeBy: {NativeBy}')
        df = df[(df['setID'].isin(setIDs)) & (df['NativeBy']==NativeBy)]
        print(f'{label}_df:\n{df}')

        #################################################
        ## Determine the scope of the analysis
        if scope in ['full', 'last10']:
            if scope == 'full':
                scope_list = [f'full', f'0-10%', f'10-20%', f'20-30%', f'30-40%', f'40-50%', f'50-60%', f'60-70%', f'70-80%', f'80-90%', f'90-100%']
            else:
                scope_list = [f'90-100%']

        else:
            raise ValueError(f'Scope can only be full or last10')

        ########################################################################################
        ## for each protein calculate the <R> and confidence intervals 
        df_stats = {'setIDs':[], 'NativeBy':[], 'Label':[], 'test':[], 'statistic':[], 'pvalue':[]}

        for key in scope_list:

            data1 = df[df['setID'] == setIDs[0]][key].values
            data2 = df[df['setID'] == setIDs[1]][key].values
            
            if test == 'permutation':
                res = permutation_test((data1, data2), statistic, vectorized=True, alternative='greater')
            elif test == 'ttest':
                res = ttest_ind(data1, data2, alternative='greater', equal_var=False)
            statistic_val = res.statistic
            pvalue = res.pvalue

            df_stats['setIDs'] += [setIDs]
            df_stats['NativeBy'] += [NativeBy]
            df_stats['Label'] += [key]
            df_stats['test'] += [test]
            df_stats['statistic'] += [statistic_val]
            df_stats['pvalue'] += [pvalue]

        df_stats = pd.DataFrame(df_stats)
        print(df_stats)
        outfile = os.path.join(self.data_path, f'{label}_{test}_TwoSampleStats_Scope-{scope}_NativeBy{NativeBy}.csv')
        df_stats.to_csv(outfile, index=False)
        logging.info(f'SAVED: {outfile}')  
        return df_stats   
    #######################################################################################

    #######################################################################################
    def Plot_OneSampleStats(self, df, outfiletag='temp', scope='full'):
        """
        Plots the two sample stats for two sets of data.
        df is a OneSampleStats dataframe with the mean, median, std, and conf. intervals 
        outfiletag is just a string appended to the image file name
        scope is the level at which data was analyzed. all chunks of the trajectory were analyzed (full) or just the last 10% (last10)
        """     
        print(f'Plotting:\n{df}')
        outfile = os.path.join(self.plot_path, f'{outfiletag}_Stats_Scope-{scope}_plot.png')
        outfile_csv = os.path.join(self.plot_path, f'{outfiletag}_Stats_Scope-{scope}_plot.csv')

        #################################################
        ## Determine the scope of the analysis
        if scope in ['full', 'last10']:
            if scope == 'full':
                fig, axes = plt.subplots(3, 1, figsize=(4, 6), sharex=True)
            else:
                print(f'SCOPE: {scope}')
                fig, axes = plt.subplots(3, 1, figsize=(2, 6), sharex=True)
        else:
            raise ValueError(f'Scope can only be full or last10')
        
        # First plot: avg with error bars (lb and ub)
        axes[0].errorbar(df['Label'], df['avg'], yerr=[df['avg'] - df['lb'], df['ub'] - df['avg']], 
                        fmt='o', capsize=5, label='Average')
        axes[0].set_ylabel('Average (avg)')
        #axes[0].set_title('Average with Error Bars')
        
        # Second plot: median
        axes[1].plot(df['Label'], df['median'], 'o', color='orange', label='Median')
        axes[1].set_ylabel('Median')
        #axes[1].set_title('Median')

        # Third plot: pvalue with log scale
        axes[2].plot(df['Label'], df['pvalue'], 'o', color='red', label='P-Value')
        axes[2].set_yscale('log')
        axes[2].set_ylabel('P-Value (log scale)')
        #axes[2].set_title('P-Value (Log Scale)')
        axes[2].axhline(0.05)
        
        # Set shared x-axis labels
        plt.xticks(rotation=45)
        #axes[2].set_xlabel('Label')
        # Adjust alignment of x-tick labels to be anchored at the upper right
        for tick in axes[2].get_xticklabels():
            tick.set_ha('right')  # Set horizontal alignment to right
            tick.set_va('top')    # Set vertical alignment to top
        
        # Layout adjustments
        plt.suptitle(outfiletag, fontsize=10)
        # Get current xlim and add 0.5 to either side
        current_xlim = plt.gca().get_xlim()
        new_xlim = (current_xlim[0] - 0.5, current_xlim[1] + 0.5)
        plt.xlim(new_xlim)
        plt.tight_layout()
        plt.savefig(outfile)
        logging.info(f'SAVED: {outfile}')
        print(f'SAVED: {outfile}')

        df.to_csv(outfile_csv, index=False)
        print(f'SAVED: {outfile_csv}')
    #######################################################################################

    ########################################################################################
    def Plot_TwoSampleStats(self, df1, df2, test_df, outfiletag='temp', scope='full'):     
        """
        Plots the two sample stats for two sets of data.
        df1 is a OneSampleStats dataframe with the mean, median, std, and conf. intervals for dataset 1
        df2 is a OneSampleStats dataframe with the mean, median, std, and conf. intervals for dataset 2
        test_df is the TwoSampleStats dataframe with the test statistic and pvalue for the comparison of datasets 1 and 2
        outfiletag is just a string appended to the image file name
        scope is the level at which data was analyzed. all chunks of the trajectory were analyzed (full) or just the last 10% (last10)
        """       
        ########################################################################################
        ## calculate the statstics between the two setIDs 1 and 2 for Rfull and all the blocks
        # save both a image with the histograms and a csv file with the results of the permutation test
        #print(f'df1:\n{df1}')
        #print(f'df2:\n{df2}')
        #print(f'test_df:\n{test_df}')

        #print(f'Plotting:\n{df}')
        outfile = os.path.join(self.plot_path, f'{outfiletag}_CompStats_Scope-{scope}_Plot.png')
        outfile_csv = os.path.join(self.plot_path, f'{outfiletag}_CompStats_Scope-{scope}_Plot.csv')

        #################################################
        ## Determine the scope of the analysis
        if scope in ['full', 'last10']:
            if scope == 'full':
                fig, axes = plt.subplots(4, 1, figsize=(4, 6), sharex=True)
            else:
                fig, axes = plt.subplots(4, 1, figsize=(2, 6), sharex=True)
        else:
            raise ValueError(f'Scope can only be full or last10')
        
        # First plot: avg with error bars (lb and ub)
        axes[0].errorbar(df1['Label'], df1['avg'], yerr=[df1['avg'] - df1['lb'], df1['ub'] - df1['avg']], 
                        fmt='o', capsize=5, label=f'Low Mis. Prone', color='red')
        axes[0].errorbar(df2['Label'], df2['avg'], yerr=[df2['avg'] - df2['lb'], df2['ub'] - df2['avg']], 
                        fmt='o', capsize=5, label='High Mis. Prone', color='blue')
        axes[0].set_ylabel('Average (avg)')
        #axes[0].set_title('Average with Error Bars')
        
        # Second plot: median
        axes[1].plot(df1['Label'], df1['median'], 'o', color='red', label=f'Low Mis. Prone')
        axes[1].plot(df2['Label'], df2['median'], 'o', color='blue', label=f'High Mis. Prone')
        axes[1].set_ylabel('Median')
        axes[0].legend(fontsize=8)

        # Third plot: pvalue with log scale
        axes[2].plot(test_df['Label'], test_df['statistic'], 'o', color='black', label='Eff. Size')
        axes[2].set_ylabel('Eff. Size')

        # Fourth plot: pvalue with log scale
        axes[3].plot(test_df['Label'], test_df['pvalue'], 'o', color='black', label='P-Value')
        axes[3].set_yscale('log')
        axes[3].set_ylabel('P-Value (log scale)')
        axes[3].axhline(0.05)

        # Set shared x-axis labels
        plt.xticks(rotation=45)
        #axes[2].set_xlabel('Label')
        # Adjust alignment of x-tick labels to be anchored at the upper right
        for tick in axes[3].get_xticklabels():
            tick.set_ha('right')  # Set horizontal alignment to right
            tick.set_va('top')    # Set vertical alignment to top
        
        # Layout adjustments
        plt.suptitle(outfiletag)
        plt.tight_layout()
        plt.savefig(outfile)
        logging.info(f'SAVED: {outfile}')
        print(f'SAVED: {outfile}')
    #######################################################################################

#######################################################################################
def bootstrap(data):
    boot_means = []
    for b in range(10000):
        boot_samp = np.random.choice(data, size=len(data))
        boot_mean = np.mean(boot_samp)
        #print(b, boot_mean)
        boot_means += [boot_mean]

    lb = np.percentile(boot_means, 2.5)
    ub = np.percentile(boot_means, 97.5)
    return (lb, ub)
#######################################################################################

#######################################################################################
def get_stats(arr):
    """
    Get the <> and 95% ci for a stats array
    """
    mean = np.mean(arr)
    std = np.std(arr)
    lb, ub = bootstrap(arr)
    median = np.median(arr)
    return (median, mean, std, lb, ub)
#######################################################################################

#######################################################################################
def statistic(x, y, axis):
    return np.mean(x, axis=axis) - np.mean(y, axis=axis)
#######################################################################################

############## MAIN #################
def main():
    
    script_name = f'CompareMisfoldingPropensity'
    parser = argparse.ArgumentParser(description="Process user specified arguments")
    parser.add_argument("--outpath", type=str, required=True, help="Path to output directory")
    parser.add_argument("--candidates", type=str, required=True, help="A file containing two columns. The candidate tag and the groupID")
    parser.add_argument("--toplevel", type=str, required=True, help="file containing relative paths to either native state GQ files or the MSM file for various proteins")
    parser.add_argument("--outname", type=str, required=True, help="base name for output files")
    parser.add_argument("--Mirrorfile", type=str, required=True, help="file containing trajectories identified as a mirror")

    args = parser.parse_args()

    ## make output folder
    if not os.path.exists(args.outpath):
        os.makedirs(args.outpath)
        print(f'Made directory: {args.outpath}')

    ## make logging dir
    logs = os.path.join(args.outpath, 'logs')
    if not os.path.exists(logs):
        os.makedirs(logs)
        print(f'Made directory: {logs}')    
    
    ## make DATA dir
    data_path = os.path.join(args.outpath, 'DATA')
    if not os.path.exists(data_path):
        os.makedirs(data_path)
        print(f'Made directory: {data_path}')  
   

    # Setup logging configuration
    logfile = os.path.join(logs, f'{args.outname}.log')
    print(f'logfile: {logfile}')
    logging.basicConfig(filename=logfile, level=logging.INFO, format='%(asctime)s %(message)s')
    logging.info(f'{"#"*50}NEW RUN {script_name}{"#"*50}')

    
    # Step 0: initialize the simulation object 
    anal = Analysis(args)

    # Define a file to save the intermeditate dictionary too for quicker loading
    DATA_outfile = os.path.join(data_path, f'DATA.pkl')
    logging.info(f'DATA_outfile: {DATA_outfile}')

    if not os.path.exists(DATA_outfile):
        logging.info(f'No DATA.pkl file found. Generating from scratch.')
        # Step 1: load the G and Q data
        anal.load_OP()

        # Step 2: for each candidate get the native G and Q states
        anal.get_nativeSIM_stats()
        
        # Step 3: Identify the native state in the MSM data
        anal.find_native_state()

        # Save master dictionary to a file
        with open(DATA_outfile, 'wb') as file:
            pickle.dump(anal.data, file) 
        logging.info(f'SAVED: {DATA_outfile}')       
        
    elif os.path.exists(DATA_outfile):        
        logging.info(f'DATA.pkl file found.')
        # Load dictionary from the file
        with open(DATA_outfile, 'rb') as file:
            anal.data = pickle.load(file)
        logging.info(f'LOADED: {DATA_outfile}')
    
    # Step 4: Calculate metrics, get stats, and plot
    for NativeBy in ['Ref', 'MSS']:

        ###############################################################################
        # Fraction of misfolded frames and compare the distributions from set 1 and 2
        Fract_misfolded_df = anal.CalcFractMisfolded(NativeBy=NativeBy, scope='full') 
        print(f'Fract_misfolded_df:\n{Fract_misfolded_df}')
        Fract_misfolded_set1_stats = anal.OneSampleStats(Fract_misfolded_df, setID=1, NativeBy=NativeBy, test_mean=None, label='Fract_misfolded', scope='full')
        Fract_misfolded_set2_stats = anal.OneSampleStats(Fract_misfolded_df, setID=2, NativeBy=NativeBy, test_mean=None, label='Fract_misfolded', scope='full')
        anal.Plot_OneSampleStats(Fract_misfolded_set1_stats, outfiletag=f'Fract_misfolded_set1_NativeBy{NativeBy}', scope='full')
        anal.Plot_OneSampleStats(Fract_misfolded_set2_stats, outfiletag=f'Fract_misfolded_set2_NativeBy{NativeBy}', scope='full')

        perm_df = anal.TwoSampleStats(Fract_misfolded_df, setIDs=(1,2), NativeBy=NativeBy, test='permutation', label='Fract_misfolded', scope='full')
        ttest_df = anal.TwoSampleStats(Fract_misfolded_df, setIDs=(1,2), NativeBy=NativeBy, test='ttest', label='Fract_misfolded', scope='full')
        anal.Plot_TwoSampleStats(Fract_misfolded_set1_stats, Fract_misfolded_set2_stats, perm_df, outfiletag=f'Fract_misfolded_set1V2_NativeBy{NativeBy}', scope='full')
        ###############################################################################


    print(f'logfile: {logfile}')

if __name__ == "__main__":
    start_time = time.time()
    main()
    end_time = time.time()

print(f'NORMAL TERMINATION: {time.time() - start_time}')
logging.info(f'NORMAL TERMINATION: {time.time() - start_time}')